{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8470de3b-8707-48fc-af3a-9bec1925ab6a",
   "metadata": {},
   "source": [
    "# Querying Elasticsearch\n",
    "\n",
    "Delvin So\n",
    "\n",
    "This notebook queries our elasticsearch instance for high-engagement tweets related to vaccines and masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dfda8dd-cd56-4a8b-a820-40bcfc36790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from pprint import pprint\n",
    "import os \n",
    "\n",
    "def make_if_not_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "        \n",
    "def add_doc_md(hit) -> dict:  \n",
    "    \"\"\"\n",
    "    extracts tweet id and es score, adding it to the dictionary (_source\n",
    "    \"\"\"\n",
    "    d = hit.to_dict()\n",
    "    d['status_id'] = hit.meta.id\n",
    "    d['es_score'] = hit.meta.score\n",
    "    \n",
    "    if 'date' in hit: \n",
    "        del hit['date']\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "from itertools import islice\n",
    "import csv\n",
    "\n",
    "# https://stackoverflow.com/questions/63298676/processing-csv-iteratively-3-rows-at-a-time-in-python       \n",
    "def chunks(iterable, n) -> tuple:\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "       chunk = tuple(islice(it, n))\n",
    "       if not chunk:\n",
    "           return\n",
    "       yield chunk\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a94837-3c66-4283-bf5d-41a03c3215af",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "client = Elasticsearch(timeout=60, max_retries=10, retry_on_timeout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40939b29-d1e7-4d21-90a3-fde91a1f80b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # https://github.com/elastic/elasticsearch-dsl-py/issues/817#issuecomment-372271460\n",
    "# from multiprocessing import Pool\n",
    "\n",
    "# SLICES = 4                                                       \n",
    "\n",
    "# def dump_slice(slice_no):                                                       \n",
    "#     s = Search(using=client, index=\"twitter\").query('match', **{'text': 'mask'})#.filter('term', **{'verified':True})                                                               \n",
    "#     s = s.extra(slice={\"id\": slice_no, \"max\": SLICES})                          \n",
    "#     #for d in s.scan():                                                          \n",
    "#     #   print(d.meta.id)\n",
    "#     df = pd.DataFrame([add_doc_id(hit) for hit in s.scan()])\n",
    "#     return df\n",
    "# pool = Pool(SLICES)                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84ed6f-68d5-4672-9949-a319c9e5c885",
   "metadata": {},
   "source": [
    "## Setting up the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec63936-d48c-4728-ac8c-5516be070057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'bool': {'must': [{'query_string': {'default_field': 'text',\n",
       "      'query': '*vaccin* OR *vax*'}}],\n",
       "   'should': [{'range': {'followers_count': {'gte': 5000}}},\n",
       "    {'range': {'favorite_count': {'gte': 5000}}},\n",
       "    {'range': {'retweet_count': {'gte': 5000}}}],\n",
       "   'minimum_should_match': 1}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s = Search(using=client, index = 'twitter').query('query_string', **{\"default_field\" : \"text\", \"query\" : \"*vaccin* OR *vax*\"})\n",
    "# s = Search(using=client, index = 'twitter').query('query_string', **{\"default_field\" : \"text\", \"query\" : \"*vaccin* OR *vax*\"})\n",
    "# s = Search(using=client, index = 'twitter').query('wildcard', **{\"text\" :  {\"value\" : \"*vaccin*\"}}) # 36 minutes\n",
    "# s = Search(using=client, index = 'twitter').query('wildcard', **{\"text\" :  {\"value\" : \"*vax*\"}}) # few minutes\n",
    "# s = Search(using=client, index = 'twitter').query('wildcard', **{\"text\" :  {\"value\" : \"*mask*\"}}) # 23 minutes\n",
    "\n",
    "\n",
    "q = Q('bool',\n",
    "    must=[Q(\"query_string\",  **{\"default_field\" : \"text\", \"query\" : \"*vaccin* OR *vax*\"})],\n",
    "    should=[Q(\"range\", **{ \"followers_count\": { \"gte\" : 5000 }} ), \n",
    "            Q(\"range\", **{ \"favorite_count\": { \"gte\" : 5000 }} ),\n",
    "            Q(\"range\", **{ \"retweet_count\": { \"gte\" : 5000 }}),\n",
    "#             Q(\"range\", **{ \"quote_count\": { \"gte\" : 500 }}),\n",
    "#             Q(\"range\", **{ \"reply_count\": { \"gte\" : 500 }} ),\n",
    "#             Q(\"term\", **{ \"verified\": True }) \n",
    "           ],\n",
    "    minimum_should_match=1,\n",
    ")\n",
    "\n",
    "\n",
    "s = Search(using = client, index = 'twitter').query(q)\n",
    "\n",
    "# sanity check\n",
    "s.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ffa8790-45e6-4747-9ae2-e5f61ffeac55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 3764161,\n",
       " '_shards': {'total': 5, 'successful': 5, 'skipped': 0, 'failed': 0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json \n",
    "\n",
    "response = requests.post('http://localhost:9200/twitter/_count', \n",
    "                         headers={ 'Content-Type': 'application/json',},\n",
    "                         data=json.dumps(s.to_dict()))\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb847b-68b0-4c3d-bfee-0ebf4e4dab61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for hit in s[:10]:\n",
    "#     print(add_doc_md(hit))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb190d-dcf9-48d2-b6ad-c38d10f81cf9",
   "metadata": {},
   "source": [
    "The following code takes an iterable (`s.scan()`)and converts it into 'chunks', which are individually processed and saved down into a csv. This is far more efficient in contrast to iterating through the entire iterable, storing it in memory and then saving it down to a csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5158b4ac-c939-495f-a57d-0fab4c2bf41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "Done! Took 11.916052277882894 minutes\n"
     ]
    }
   ],
   "source": [
    "make_if_not_exists('data_out')\n",
    "\n",
    "start_time = time.time() \n",
    "chunk_size = 100000\n",
    "for i, chunk in enumerate(chunks(s.scan(), chunk_size)):\n",
    "    if (i % 10) == 0:\n",
    "        print(i)\n",
    "    with open(os.path.join('data_out', f\"wildcard_{str(i).zfill(2)}.csv\"), \"w\") as f:\n",
    "        header_present  = False\n",
    "        for hit in chunk:\n",
    "            my_dict = add_doc_md(hit) \n",
    "            if not header_present:\n",
    "                w = csv.DictWriter(f, my_dict.keys())\n",
    "                w.writeheader()\n",
    "                header_present = True\n",
    "            w.writerow(my_dict)\n",
    "end_time = time.time()\n",
    "print('Done! Took {} minutes'.format((end_time - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a6d8eb-9e5c-433c-9303-188ba1d52c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
